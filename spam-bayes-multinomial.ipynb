{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Spam classifier: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Multinomial event model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will apply the naive Bayesian classifier of Laplace smoothing for spam filter training based on data [SpamAssassin Public Corpus](http://spamassassin.apache.org/publiccorpus/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Result of applying this model is better than multivariate Bernoulli event model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Process of the data cleaning was performed in [`spam-data-preparation.ipynb`](spam-data-preparation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "emails_tokenized_ham = load_json_from_file(\"emails-tokenized-ham.json\")\n",
    "emails_tokenized_spam = load_json_from_file(\"emails-tokenized-spam.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab = load_json_from_file(\"vocab.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's represent each email as $ n $-dimensional vector $ \\left [x_1, x_2, ..., x_n \\right] $, where $ x_i $ is an index of the $ i $-th word of this email in the dictionary $ V $, and $ n $ is a number of words in the email letter.\n",
    "\n",
    "For example, _ \"Buy gold watches. Buy now.\" _ can be coded as: $ \\left[3953, 11890, 32213, 3953, 20330\\right] $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def email_to_vector_multinomial(email_words, vocab):\n",
    "    email_vec = np.zeros(len(email_words), dtype=\"int32\")\n",
    "    \n",
    "    for word in email_words:\n",
    "        if word in vocab:\n",
    "            indices = [i for i, x in enumerate(email_words) if x == word] \n",
    "            email_vec[indices] = vocab[word]\n",
    "            \n",
    "    return email_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's encode all emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [\n",
    "    email_to_vector_multinomial(email, vocab)\n",
    "    for email in emails_tokenized_ham + emails_tokenized_spam\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = np.array([0] * len(emails_tokenized_ham) + [1] * len(emails_tokenized_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's look at a few random emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_emails = [emails_tokenized_ham[10], emails_tokenized_ham[70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'seen', 'discuss', 'articl', 'approach', 'thank', 'httpaddress', 'hell', 'rule', 'tri', 'accomplish', 'someth', 'thoma', 'alva', 'edison', 'sf', 'net', 'email', 'sponsor', 'osdn', 'tire', 'old', 'cell', 'phone', 'get', 'new', 'free', 'httpaddress', 'spamassassin', 'devel', 'mail', 'list', 'emailaddress', 'httpaddress']\n",
      "\n",
      "['fri', 'number', 'aug', 'number', 'tom', 'wrote', 'xvid', 'number', 'project', 'make', 'gpl', 'divx', 'codec', 'sigma', 'design', 'number', 'sorri', 'sigma', 'design', 'number', 'number', 'httpaddress']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for email in sample_emails:\n",
    "    print(email)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email vector: [12866 26186  7632  1574  1361 29410 13468 12862 25408 30214   173 27396\n",
      " 29564   872  8567 26411 19758  8849 27722 21116 29770 20748  4549 22215\n",
      " 11528 19855 10871 13468 27540  7314 17535 16947  8851 13468]\n",
      "Dimensionality: (34,)\n",
      "\n",
      "Email vector: [10946 20419  1845 20419 29891 33008 33256 20419 23298 17594 12021  7779\n",
      "  5370 26756  7232 20419 27443 26756  7232 20419 20419 13468]\n",
      "Dimensionality: (22,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for email in sample_emails:\n",
    "    email_vec = email_to_vector_multinomial(email, vocab)\n",
    "    \n",
    "    print(\"Email vector:\", email_vec)\n",
    "    print(\"Dimensionality:\", email_vec.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Splitting of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 4987\n",
      "# Test:  555\n"
     ]
    }
   ],
   "source": [
    "print(\"# Train:\", len(X_train))\n",
    "print(\"# Test: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive Bayesian classifier training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's count the total number of words in ham and spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_words(emails, y, c):\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(emails)):\n",
    "        if y[i] == c:\n",
    "            k = k + len(emails[i])\n",
    "        elif c == \"all\":\n",
    "            k = k + len(emails[i])\n",
    "    return(k)    \n",
    "\n",
    "ham_total_words_train = count_words(X_train, y_train, 0)\n",
    "spam_total_words_train = count_words(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's compute the class priors for ham and spam emails.\n",
    "\n",
    "$\\log{P(ham)} = \\log{\\frac{1\\{y=ham\\}}{m}}$\n",
    "\n",
    "$\\log{P(spam)} = \\log{\\frac{1\\{y=spam\\}}{m}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ham_log_prior = np.log(ham_total_words_train / count_words(X_train, y_train, \"all\"))\n",
    "spam_log_prior = np.log(spam_total_words_train / count_words(X_train, y_train, \"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's compute likelihood $\\log{\\phi_{word\\,|\\,class}}$ for each word in the dictionary. We will also apply Laplace smoothing to avoid division by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$\\log{\\phi_{word\\,|\\,class}} = \\log{\\frac{\\sum_{i=1}^{m} \\sum_{j=1}^{n_i} {1\\{x_{j}^{(j)}=word \\, \\land \\, y=class\\}} + 1}{\\sum_{i=1}^{m}{1\\{y=class\\}n_i} \\,+\\, |V|}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's create empty vectors $\\log{\\phi_{word \\, | \\, ham}}$ and $\\log{\\phi_{word \\, | \\, spam}}$ and fill them for each word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ham_log_phi = np.zeros(len(vocab), dtype=\"float64\")\n",
    "spam_log_phi = np.zeros(len(vocab), dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_number_words(c, word_index):\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        if y_train[i] == c:\n",
    "            k = k + np.count_nonzero(X_train[i] == word_index)\n",
    "    return(k)   \n",
    "\n",
    "ham_word_counts = np.zeros(len(vocab))\n",
    "spam_word_counts = np.zeros(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for word_index in progressbar(range(len(vocab)), desc=\"Training\"):\n",
    "    ham_log_phi[word_index] = np.log((count_number_words(0, word_index) + 1) / (ham_total_words_train + len(vocab)))\n",
    "    spam_log_phi[word_index] = np.log((count_number_words(1, word_index) + 1) / (spam_total_words_train + len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$\\log P(y=class\\,|\\,words) = \\log \\frac{P(words\\,|\\,y=class) P(y=class)}{P(words)} = \\frac{\\sum_{i=1}^{n} \\log P(words_i\\,|\\,y=class) + \\log P(y=class)}{P(words)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The denominator $P(words)$ is the same for both classes, so it will be ignored in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    y_pred = np.zeros(len(X))\n",
    "\n",
    "    for i in progressbar(range(len(y_pred)), desc=\"Predict\"):\n",
    "        email_vector = X[i]\n",
    "        \n",
    "        ham_posterior = ham_log_phi[email_vector].sum() + ham_log_prior\n",
    "        spam_posterior = spam_log_phi[email_vector].sum() + spam_log_prior\n",
    "\n",
    "        # Whichever class has the bigger posterior probability, wins.\n",
    "        y_pred[i] = 0 if ham_posterior > spam_posterior else 1\n",
    "    \n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation of prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(X_train)\n",
    "pred_test = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy_train = 1 - np.sum(pred_train != y_train) / len(y_train)\n",
    "accuracy_test = 1 - np.sum(pred_test != y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:   97.714%\n",
      "Test accuracy:       97.477%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:   {0:.3f}%\".format(accuracy_train * 100))\n",
    "print(\"Test accuracy:       {0:.3f}%\".format(accuracy_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
